{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- includes\n",
    "  - determining the computing device\n",
    "  - model name\n",
    "  - csv path\n",
    "  - destinated json line path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    LlamaModel,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    " \n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\" \n",
    "CSV_PATH = \"ObesityDataSet.csv\"\n",
    "TRAIN_JSON_PATH = \"ObesityTrainDataSet.jsonl\"\n",
    "TEST_JSON_PATH = \"ObesityTestDataSet.jsonl\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hugging face log in\n",
    "\n",
    "- hugging face requires login for access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dbe4a480554750a9e23b9f788c2478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing\n",
    "\n",
    "- convert the csv file to json line file\n",
    "- split the data into train data and test data, 8:2 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label maps\n",
    "id2label = {0:\"Insufficient_Weight\", 1:\"Normal_Weight\" ,2:\"Overweight_Level_I\" , 3:\"Overweight_Level_II\" , 4:\"Obesity_Type_I\" , 5:\"Obesity_Type_II\" , 6:\"Obesity_Type_III\" }\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.rename(columns={\"NObeyesdad\": \"label\"})\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Convert label column from string to integers using label2id\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label2id)\n",
    "test_df[\"label\"] = test_df[\"label\"].map(label2id)\n",
    "\n",
    "train_df.to_json(TRAIN_JSON_PATH, orient=\"records\", lines=True)\n",
    "test_df.to_json(TEST_JSON_PATH, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset\n",
    "\n",
    "- load both test and train datasets into dataset variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad2be38d2ca4a01af80fef400711c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2107234a7b4d9988689602a30e7259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'label'],\n",
       "        num_rows: 1688\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'label'],\n",
       "        num_rows: 423\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_JSON_PATH, \"test\": TEST_JSON_PATH})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading model & tokenizer & data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=7, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "    ).to(DEVICE)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    texts = [\n",
    "        f\"gender: {g}, age: {a}, height: {h}, weight: {w}, family_history_with_overweight: {f}, favc: {favc}, fcvc: {fcvc}, ncp: {ncp}, caec: {caec}, smoke: {s}, ch2o: {ch2o}, scc: {scc}, faf: {faf}, tue: {tue}, calc: {calc}, mtrans: {mtrans}\"\n",
    "        for g, a, h, w, f, favc, fcvc, ncp, caec, s, ch2o, scc, faf, tue, calc, mtrans in zip(\n",
    "            examples[\"Gender\"], \n",
    "            examples[\"Age\"], \n",
    "            examples[\"Height\"], \n",
    "            examples[\"Weight\"], \n",
    "            examples[\"family_history_with_overweight\"], \n",
    "            examples[\"FAVC\"], \n",
    "            examples[\"FCVC\"], \n",
    "            examples[\"NCP\"], \n",
    "            examples[\"CAEC\"], \n",
    "            examples[\"SMOKE\"], \n",
    "            examples[\"CH2O\"], \n",
    "            examples[\"SCC\"], \n",
    "            examples[\"FAF\"], \n",
    "            examples[\"TUE\"], \n",
    "            examples[\"CALC\"], \n",
    "            examples[\"MTRANS\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        texts, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Convert labels to PyTorch tensor\n",
    "    encoding[\"labels\"] = [label for label in examples[\"label\"]]\n",
    "    \n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gender': 'Female', 'Age': 21.0, 'Height': 1.63, 'Weight': 60.0, 'family_history_with_overweight': 'yes', 'FAVC': 'yes', 'FCVC': 3.0, 'NCP': 3.0, 'CAEC': 'Always', 'SMOKE': 'yes', 'CH2O': 2.0, 'SCC': 'no', 'FAF': 2.0, 'TUE': 0.0, 'CALC': 'Sometimes', 'MTRANS': 'Public_Transportation', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce218e0feb2a427c979a0f65dc6f88ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb050ef2fc0e48a2a6f137366e2fcb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/423 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1688\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 423\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = torch.tensor(predictions).to(DEVICE)\n",
    "    labels = torch.tensor(labels).to(DEVICE)\n",
    "\n",
    "    predictions = torch.argmax(predictions, dim=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'label', 'input'],\n",
       "    num_rows: 423\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_to_string(data):\n",
    "    if isinstance(data, str):\n",
    "        data = json.loads(data)\n",
    "    \n",
    "    if not data:\n",
    "        return \"\"\n",
    "    \n",
    "    formatted_string =  \", \".join([f\"{k}: {v}\" for k, v in data.items() if k != \"label\"])\n",
    "    return {\"input\": formatted_string}\n",
    "\n",
    "test_inputs = dataset[\"test\"].map(dict_to_string)\n",
    "test_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "--------------------------\n",
      "Accuracy: 0.15130023640661938\n"
     ]
    }
   ],
   "source": [
    "print(\"Untrained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "isCorret_untrained = 0;\n",
    "total_untrained = 0;\n",
    "accuracy_untrained = 0;\n",
    "for text in test_inputs:\n",
    "    total_untrained += 1\n",
    "    inputs = tokenizer.encode(text[\"input\"], return_tensors=\"pt\").to(DEVICE)\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    if predictions == text[\"label\"]:\n",
    "        isCorret_untrained += 1\n",
    "\n",
    "accuracy_untrained = isCorret_untrained / total_untrained\n",
    "print(f\"Accuracy: {accuracy_untrained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(task_type='SEQ_CLS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=8, target_modules={'q_proj', 'o_proj', 'k_proj', 'v_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, eva_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,718,272 || all params: 1,237,549,056 || trainable%: 0.1388\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-4\n",
    "batch_size = 1\n",
    "num_epochs = 2\n",
    "\n",
    "# Explicitly set padding token in the model config\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= MODEL_NAME + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20988\\1999590121.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID in tokenizer: 128256\n",
      "Pad token ID in model config: 128256\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad token ID in tokenizer:\", tokenizer.pad_token_id)\n",
    "print(\"Pad token ID in model config:\", model.config.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "c:\\msys64\\mingw64\\bin\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='422' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [422/422 05:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.786767</td>\n",
       "      <td>{'accuracy': 0.2576832151300236}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.681527</td>\n",
       "      <td>{'accuracy': 0.3877068557919622}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\msys64\\mingw64\\bin\\Lib\\site-packages\\peft\\utils\\save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "c:\\msys64\\mingw64\\bin\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "c:\\msys64\\mingw64\\bin\\Lib\\site-packages\\peft\\utils\\save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "c:\\msys64\\mingw64\\bin\\Lib\\site-packages\\peft\\utils\\save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=422, training_loss=1.7925796870371742, metrics={'train_runtime': 336.2494, 'train_samples_per_second': 10.04, 'train_steps_per_second': 1.255, 'total_flos': 1.011053739638784e+16, 'train_loss': 1.7925796870371742, 'epoch': 2.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\msys64\\mingw64\\bin\\Lib\\site-packages\\peft\\utils\\save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save_pretrained(MODEL_NAME + \"-lora-text-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model predictions:\n",
      "--------------------------\n",
      "Accuracy: 0.3049645390070922\n"
     ]
    }
   ],
   "source": [
    "print(\"trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "isCorret_trained = 0;\n",
    "total_trained = 0;\n",
    "accuracy_trained = 0;\n",
    "for text in test_inputs:\n",
    "    total_trained += 1\n",
    "    inputs = tokenizer.encode(text[\"input\"], return_tensors=\"pt\").to(DEVICE)\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    if predictions == text[\"label\"]:\n",
    "        isCorret_trained += 1\n",
    "\n",
    "accuracy_trained = isCorret_trained / total_trained\n",
    "print(f\"Accuracy: {accuracy_trained}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
